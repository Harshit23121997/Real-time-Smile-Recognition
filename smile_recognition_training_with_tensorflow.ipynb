{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob,os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading images from the data folder\n",
    "# label, smile = 1, neutral = 0\n",
    "(img_width, img_height) = (45, 25)\n",
    "def load_images_from_folder(folder):\n",
    "    (images, lables, names, id) = ([], [], {}, 0)\n",
    "    for (subdirs, dirs, files) in os.walk(folder):\n",
    "        print subdirs, dirs\n",
    "        for subdir in dirs:\n",
    "            names[id] = subdir\n",
    "            subjectpath = os.path.join(folder, subdir)\n",
    "            for filename in os.listdir(subjectpath):\n",
    "                path = subjectpath + '/' + filename\n",
    "                lable = id\n",
    "                img = cv2.imread(path, 0)\n",
    "                img = cv2.resize(img,(img_width, img_height))\n",
    "                images.append(img)\n",
    "                lables.append(int(lable))\n",
    "            id += 1\n",
    "        \n",
    "        return images, lables, names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/ ['neutral', 'smile']\n"
     ]
    }
   ],
   "source": [
    "X,Y,classes = load_images_from_folder(\"./data/\")\n",
    "\n",
    "(X,Y) = [np.array(lis) for lis in [X, Y]]\n",
    "Y = pd.get_dummies(Y) #concerting labels to one-hot, Used Pandas for it. need to do it with numpy\n",
    "# print Y\n",
    "# print len(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height of the image:  25\n",
      "Width of the image:   45\n",
      "Total number of data: 144\n"
     ]
    }
   ],
   "source": [
    "print \"Height of the image:  \" + str(X.shape[1])\n",
    "print \"Width of the image:   \"  + str(X.shape[2])\n",
    "print \"Total number of data: \"+ str(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of train data: 96\n",
      "lenght of test data:  48\n"
     ]
    }
   ],
   "source": [
    "print \"lenght of train data: \"+str(len(X_train))\n",
    "print \"lenght of test data:  \"+str(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten: (96, 1125)\n",
      "test_set_x_flatten : (48, 1125)\n",
      "[[170 181 179 ..., 154 159 155]\n",
      " [201 198 199 ..., 181 178 175]\n",
      " [143 143 146 ..., 224 225 226]\n",
      " ..., \n",
      " [163 164 162 ..., 151 150 150]\n",
      " [146 147 143 ...,  14  11   7]\n",
      " [184 191 188 ...,  83  70  88]]\n"
     ]
    }
   ],
   "source": [
    "train_set_x_flatten = X_train.reshape(X_train.shape[0],-1)\n",
    "test_set_x_flatten = X_test.reshape(X_test.shape[0],-1)\n",
    "print \"train_set_x_flatten: \"+str(train_set_x_flatten.shape)\n",
    "print \"test_set_x_flatten : \"+str(test_set_x_flatten.shape)\n",
    "\n",
    "print train_set_x_flatten\n",
    "\n",
    "index = 35\n",
    "# plt.imshow(X_train[index])\n",
    "# print (\"y = \" + str(y_train[index]) + \", it's a '\" + classes[np.squeeze(y_train[index])].decode(\"utf-8\") +  \"' picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train set: 96\n",
      "length of test set: 48\n"
     ]
    }
   ],
   "source": [
    "#Normalizing data, conveting all pixel value in range between 0-1\n",
    "\n",
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255.\n",
    "print \"length of train set: \" + str(len(train_set_x))\n",
    "print \"length of test set: \" + str(len(test_set_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train set: (96, 1125)\n",
      "shape of test set: (48, 1125)\n",
      "96 96\n"
     ]
    }
   ],
   "source": [
    "print \"shape of train set: \"+ str(train_set_x.shape)\n",
    "print \"shape of test set: \"+ str(test_set_x.shape)\n",
    "\n",
    "print len(train_set_x), len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the softmax regression using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 1125])\n",
    "W = tf.Variable(tf.zeros([1125, 2]))\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with learning rate 0.1 \n",
      "losses after per 1000 iteration:  0.693147\n",
      "losses after per 1000 iteration:  0.018768\n",
      "losses after per 1000 iteration:  0.0110425\n",
      "losses after per 1000 iteration:  0.00812822\n",
      "losses after per 1000 iteration:  0.00650153\n",
      "losses after per 1000 iteration:  0.00544514\n",
      "losses after per 1000 iteration:  0.00469743\n",
      "losses after per 1000 iteration:  0.00413739\n",
      "losses after per 1000 iteration:  0.00370071\n",
      "losses after per 1000 iteration:  0.00334993\n",
      "losses after per 1000 iteration:  0.00306153\n",
      "losses after per 1000 iteration:  0.00281997\n",
      "losses after per 1000 iteration:  0.00261454\n",
      "losses after per 1000 iteration:  0.0024376\n",
      "losses after per 1000 iteration:  0.00228353\n",
      "('accuracy with learning rate 0.1 ', 0.95833331)\n"
     ]
    }
   ],
   "source": [
    "print \"training with learning rate 0.1 \"\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for step in range(15000):\n",
    "    trainStep,loss = sess.run([train_step, cross_entropy], feed_dict={x: train_set_x, y_: y_train})\n",
    "    if step%1000==0:\n",
    "        print \"losses after per 1000 iteration: \",loss\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"accuracy with learning rate 0.1 \", sess.run(accuracy, feed_dict={x:test_set_x , y_: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.555556\n",
    "0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate 0.5\n",
      "losses after per 1000 iteration:  0.693147\n",
      "losses after per 1000 iteration:  nan\n",
      "losses after per 1000 iteration:  nan\n",
      "losses after per 1000 iteration:  nan\n",
      "losses after per 1000 iteration:  nan\n",
      "('accuracy with learning rate 0.5 ', 0.45833334)\n"
     ]
    }
   ],
   "source": [
    "print \"Training with learning rate 0.5\"\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for step in range(1000):\n",
    "    trainStep,loss = sess.run([train_step, cross_entropy], feed_dict={x: train_set_x, y_: y_train})\n",
    "    if step%200==0:\n",
    "        print \"losses after per 1000 iteration: \",loss\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"accuracy with learning rate 0.5 \", sess.run(accuracy, feed_dict={x:test_set_x , y_: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
