{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob,os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading images from the data folder\n",
    "# label, smile = 1, neutral = 0\n",
    "(img_width, img_height) = (45, 25)\n",
    "def load_images_from_folder(folder):\n",
    "    (images, lables, names, id) = ([], [], {}, 0)\n",
    "    for (subdirs, dirs, files) in os.walk(folder):\n",
    "        print subdirs, dirs\n",
    "        for subdir in dirs:\n",
    "            names[id] = subdir\n",
    "            subjectpath = os.path.join(folder, subdir)\n",
    "            for filename in os.listdir(subjectpath):\n",
    "                path = subjectpath + '/' + filename\n",
    "                lable = id\n",
    "                img = cv2.imread(path, 0) # Reading each images in grayscale\n",
    "                img = cv2.resize(img,(img_width, img_height)) # Resizing all the images\n",
    "                images.append(img)\n",
    "                lables.append(int(lable))\n",
    "            id += 1\n",
    "        \n",
    "        return images, lables, names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/ ['neutral', 'smile']\n"
     ]
    }
   ],
   "source": [
    "X,Y,classes = load_images_from_folder(\"./data/\")\n",
    "\n",
    "(X,Y) = [np.array(lis) for lis in [X, Y]]\n",
    "Y = pd.get_dummies(Y) #concerting labels to one-hot, Used Pandas for it. need to do it with numpy\n",
    "# print Y\n",
    "# print len(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height of the image:  25\n",
      "Width of the image:   45\n",
      "Total number of data: 162\n"
     ]
    }
   ],
   "source": [
    "print \"Height of the image:  \" + str(X.shape[1])\n",
    "print \"Width of the image:   \"  + str(X.shape[2])\n",
    "print \"Total number of data: \"+ str(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of train data: 97\n",
      "lenght of test data:  65\n"
     ]
    }
   ],
   "source": [
    "print \"lenght of train data: \"+str(len(X_train))\n",
    "print \"lenght of test data:  \"+str(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten: (97, 1125)\n",
      "test_set_x_flatten : (65, 1125)\n",
      "[[172 169 167 ..., 167 168 167]\n",
      " [137 120 122 ..., 129 132 128]\n",
      " [ 72  91  92 ...,  46  44  42]\n",
      " ..., \n",
      " [150 150 143 ..., 160 158 159]\n",
      " [166 161 160 ..., 154 141 144]\n",
      " [ 27  29  30 ...,  88  84  60]]\n"
     ]
    }
   ],
   "source": [
    "train_set_x_flatten = X_train.reshape(X_train.shape[0],-1)\n",
    "test_set_x_flatten = X_test.reshape(X_test.shape[0],-1)\n",
    "print \"train_set_x_flatten: \"+str(train_set_x_flatten.shape)\n",
    "print \"test_set_x_flatten : \"+str(test_set_x_flatten.shape)\n",
    "\n",
    "print train_set_x_flatten\n",
    "\n",
    "index = 35\n",
    "# plt.imshow(X_train[index])\n",
    "# print (\"y = \" + str(y_train[index]) + \", it's a '\" + classes[np.squeeze(y_train[index])].decode(\"utf-8\") +  \"' picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train set: 97\n",
      "length of test set: 65\n"
     ]
    }
   ],
   "source": [
    "#Normalizing data, conveting all pixel value in range between 0-1\n",
    "\n",
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255.\n",
    "print \"length of train set: \" + str(len(train_set_x))\n",
    "print \"length of test set: \" + str(len(test_set_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train set: (97, 1125)\n",
      "shape of test set: (65, 1125)\n",
      "97 97\n"
     ]
    }
   ],
   "source": [
    "print \"shape of train set: \"+ str(train_set_x.shape)\n",
    "print \"shape of test set: \"+ str(test_set_x.shape)\n",
    "\n",
    "print len(train_set_x), len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the softmax regression using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 1125])\n",
    "W = tf.Variable(tf.zeros([1125, 2]))\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "#cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y + 1e-50, labels = y_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with learning rate: 0.1\n",
      "losses after per 1000 iteration:  0.693147\n",
      "losses after per 1000 iteration:  0.0234265\n",
      "losses after per 1000 iteration:  0.013271\n",
      "losses after per 1000 iteration:  0.00945731\n",
      "losses after per 1000 iteration:  0.00740099\n",
      "losses after per 1000 iteration:  0.00610189\n",
      "losses after per 1000 iteration:  0.00520222\n",
      "losses after per 1000 iteration:  0.00454025\n",
      "losses after per 1000 iteration:  0.00403168\n",
      "losses after per 1000 iteration:  0.00362809\n",
      "losses after per 1000 iteration:  0.00329963\n",
      "losses after per 1000 iteration:  0.00302688\n",
      "losses after per 1000 iteration:  0.0027966\n",
      "losses after per 1000 iteration:  0.00259947\n",
      "losses after per 1000 iteration:  0.00242874\n",
      "('accuracy with learning rate: ', 0.93846154)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "print \"training with learning rate: \" + str(learning_rate)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for step in range(15000):\n",
    "    trainStep,loss = sess.run([train_step, cross_entropy], feed_dict={x: train_set_x, y_: y_train})\n",
    "    if step%1000==0:\n",
    "        print \"losses after per 1000 iteration: \",loss\n",
    "        \n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"accuracy with learning rate: \" , sess.run(accuracy, feed_dict={x:test_set_x , y_: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1125)\n",
      "[[  7.46948572e-05   9.99925256e-01]]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"/home/aquib/Desktop/smile_recognition/test/test_1.jpg\", 0) # Reading each images in grayscale \n",
    "                                                                            # test_2 is a neutral face\n",
    "                                                                            # test_1 is smile face\n",
    "img = cv2.resize(img,(img_width, img_height)) # Resizing all the images\n",
    "image=[]\n",
    "image.append(img)\n",
    "image_test = np.array(image)\n",
    "test_image_flatten = image_test.reshape(image_test.shape[0],-1)\n",
    "test_image_normalized = test_image_flatten/255.\n",
    "print test_image_normalized.shape\n",
    "#print len(test_image_normalized)\n",
    "\n",
    "x_ = tf.cast(test_image_normalized, tf.float32)\n",
    "y = tf.nn.softmax(tf.matmul(x_, W) + b)\n",
    "\n",
    "result = sess.run(y)\n",
    "indx = sess.run(tf.argmax(y))\n",
    "\n",
    "print result\n",
    "print indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
